# 현업에서의 파인튜닝&RAG 노하우
----

일자 : 3월 10일 19:30 ~ 21:00
강사 :  Eddie, 강다솔 강사

###### 목차
- 현업을 위한 합성 데이터 만드는 노하우
- 비전 거대 언어 모델 파인튜닝
- QnA


합성 데이터(Synthetic Data)
생성형 AI 기술을 이용해서 만든 데이터 (인간 관여 X)
API, for을 활용해서 자동화 가능

입력을 주고 키워드를 받아오는 방식을 이용.

파이썬 딕셔너리로 전달시 데이터프레임으로 변환 가능

근거부터 작성 후 정답을 출력하라고 하면 성능이 좋아지는 효과가 있음(COT)

파인튜닝을 잘 시키면 8b 모델과 GPT-4의 성능이 비슷하게 나오는 경우가 있음
(특정분야에서)

#3
10b 이하의 LLM에서 RAG 성능을 극대화하기 위해 모든 유형 # 추후 추가

#4
임베딩 모델 파인튜닝

## 학습 방법
### MultipleNegativesRankingLoss
- 유사도를 높이고 싶은 문장들의 쌍을 준비했을 경우 사용
- (키,값) 형태로 쌍을 만들어서 학습
작동원리
- 검색어 : 질문
- 포지티브문서 : 해당하는 문서 및 답변
- 배치 내 다른 문서 : 배치 내 포지티브가 아닌 문서 암묵적으로 네거티브 문서라고 한다

코사인 유사도 및 다른 유사도 측정방법을 사용하여
1. 검색어와 포지티브 문서 간의 유사도를 최대화
2. 검색어와 네거티브 문서 간의 유사도를 최소화

### InformationRetrieverEvaluator
- 정보 검색 모델을 평가하는 도구
- 구조(필수 입력)
1. queries(dict)
	- 질문ID = key, 질문 텍스트 = value
2. corpus(dict)
	- 문서ID = key, 문서 텍스트를 값으로 갖는 dict
3. relevant_docs(dict)
	- 질문 ID = key, 해당 질문에 관련된 문서 ID들의 set을 갖는 딕셔너리
###### 작동 방식
1. 모델이 각 질문에 대해 corpus 내 모든 문서의 관련성 점수 계산
2. 점수 기준으로 문서 정렬
3. 정렬된 결과에서 revalant_docs에 명시된 문서들의 순위를 계산
4. MMR, NDCG 등의 메트릭을 계산

###### 측정 카테고리

**Accuracy**
상위 k개의 문서 중 정답 포함 여부의 평균
**예시**:
질문이 3개 있다고 가정
* 질문 1 : [정답, 오답, 오답] → 포함(성공) (1)
* 질문 2 : [오답, 오답, 오답] → 미포함(실패) (0)
* 질문 3 : [오답, 정답, 오답] → 포함(성공) (1)
$Accuracy@3 = \frac{1+0+1}{3} → \frac{2}{3}  = 0.67$

**Precision**
상위 k개 문서 중 정답의 비율
**예시**:
질문이 3개 있다고 가정
* 질문 1 : [정답, 정답, 오답] →  $\frac{2}{3}$
* 질문 2 : [오답, 오답, 오답] →  $\frac{0}{3}$
* 질문 3 : [오답, 정답, 오답] →  $\frac{1}{3}$
$Precision@3 = \frac{\frac{2}{3} + \frac{0}{3} + \frac{1}{3}}{3} = \frac{1}{3}$

**Recall**
검색결과가 얼마나 "포괄적 "으로 정답을 포함하고 있는지 평가
각 질문에 대한 정답 개수의 비율의 평균을 구함
**예시**:
질문 1개당 정답이 2개 있다고 가정
* 질문 1 : [정답, 정답, 오답] →  $\frac{2}{2}$
* 질문 2 : [오답, 오답, 오답] →  $\frac{0}{2}$
* 질문 3 : [오답, 정답, 오답] →  $\frac{1}{2}$
$Recall@3 = \frac{\frac{2}{2} + \frac{0}{2} + \frac{1}{2}}{3} = \frac{1.5}{3} = 0.5$


**NSCG (Nomalized Discounted Cumultive Gain)**
검색 결과가 얼마나 높은 순위에 배치되었는지에 대한 평균
& 어려워서 추후에 정리...

**MRR (Mean Reciprocal Rank)**
첫 정답이 나타난 순위의 역수를 평균으로 구함
예를 들어 1등이면 1/1, 2등이면 1/2 이런 방식으로 역수를 구해 평균을 구한다.

**예시**:
질문에 대해 상위 3개의 검색결과라고 과정
* 질문 1 : [정답, 오답, 오답] → $\frac{1}{1}$
* 질문 2 : [오답, 오답, 오답] → $0$
* 질문 3 : [오답, 정답, 오답] → $\frac{1}{2}$
$MMR@3 = \frac{\frac{1}{1}+0+\frac{1}{2}}{3} = 0.5$

**MAP (Mean Average Precision)**
& 내용이 복잡하여 추후 정리 예정

### VLM
[참고링크]("https://github.com/daje0601/CookBook")

Fashion Product image
Qwen2-VL

LoRA : 저차원 행렬만 학습하여 훈련시키는 방식

EDA??
